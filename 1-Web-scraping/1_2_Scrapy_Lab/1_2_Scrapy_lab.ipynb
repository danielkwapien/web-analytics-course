{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GABRIELA MARÍN MARTÍN\n",
        "# DANIEL KWAPIEN\n",
        "# MONICA DE ALVARO MENA\n",
        "# AFINA NUROVA"
      ],
      "metadata": {
        "id": "YL5j7EHyzld6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjqGtEqMUB2O"
      },
      "source": [
        "<img src=\"https://www.uc3m.es/ss/Satellite?blobcol=urldata&blobkey=id&blobtable=MungoBlobs&blobwhere=1371573952659\">\n",
        "\n",
        "---\n",
        "\n",
        "# WEB ANALYTICS COURSE 4 - SEMESTER 2\n",
        "# BACHELOR IN DATA SCIENCE AND ENGINEERING\n",
        "\n",
        "# LAB 1.2 WEB SCRAPING WITH SCRAPY\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS1O4BW82LV6"
      },
      "source": [
        "# 0. Lab Preparation\n",
        "\n",
        "1.  Study and have clear the concepts explained in the theoretical class and the introductory lab.\n",
        "\n",
        "2.   Gain experience with the use of the [Scrapy](https://scrapy.org/). The exercises of this lab will be mainly based on the utilization of functions offered by this library.\n",
        "\n",
        "3. It is assumed students have experience in using Python notebooks. Either a local installation (e.g., local python installation + Jupyter) or a cloud-based solution (e.g., Google Colab). *We recommend the second option*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwlGXDUG2db2"
      },
      "source": [
        "# 1. Lab Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypNv8Fpi2YS7"
      },
      "source": [
        "* In this lab, we will implement a web scraper using [Scrapy](https://scrapy.org/). One of the tools explained in the theoretical class.\n",
        "\n",
        "* The lab will be done in groups of 4 people.\n",
        "\n",
        "* The lab defines a set of milestones the students must complete. Upon completing all the milestones, students should call the professor, who will check the correctness of the solution (*If the professor is busy, do not wait for them, move to the next lab*).\n",
        "\n",
        "* **The final mark will be computed as a function of the number of milestones successfully completed.**\n",
        "\n",
        "* **Each group should also share their lab notebook with the professor upon the finalization of the lab.**\n",
        "\n",
        "* In this lab we will use the [Scrapy](https://scrapy.org/) library for the creation of a web scraper, to extract information from the web. As indicated in the *Lab Preparation* section above, it is expected that students have gained experience in the use of the library before starting the first session of the lab.\n",
        "\n",
        "- It is recommended to use [Google Colab](https://colab.research.google.com/) to produce the Python notebook with the solution of the lab. Of course, if any student prefers using its local programming environment (e.g., jupyter) and python installation, they are welcome to do so."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnIUv5WsKSfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d468e96-9e8d-45fd-9020-9e5de2c621ea"
      },
      "source": [
        "!pip install scrapy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scrapy\n",
            "  Downloading Scrapy-2.11.2-py2.py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting Twisted>=18.9.0 (from scrapy)\n",
            "  Downloading twisted-24.7.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (43.0.1)\n",
            "Collecting cssselect>=0.9.1 (from scrapy)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting itemloaders>=1.0.1 (from scrapy)\n",
            "  Downloading itemloaders-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting parsel>=1.5.0 (from scrapy)\n",
            "  Downloading parsel-1.9.1-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyOpenSSL>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (24.2.1)\n",
            "Collecting queuelib>=1.4.2 (from scrapy)\n",
            "  Downloading queuelib-1.7.0-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting service-identity>=18.1.0 (from scrapy)\n",
            "  Downloading service_identity-24.1.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting w3lib>=1.17.0 (from scrapy)\n",
            "  Downloading w3lib-2.2.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting zope.interface>=5.1.0 (from scrapy)\n",
            "  Downloading zope.interface-7.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protego>=0.1.15 (from scrapy)\n",
            "  Downloading Protego-0.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting itemadapter>=0.1.0 (from scrapy)\n",
            "  Downloading itemadapter-0.9.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from scrapy) (71.0.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from scrapy) (24.1)\n",
            "Collecting tldextract (from scrapy)\n",
            "  Downloading tldextract-5.1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: lxml>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from scrapy) (4.9.4)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from scrapy) (0.7.1)\n",
            "Collecting PyDispatcher>=2.0.5 (from scrapy)\n",
            "  Downloading PyDispatcher-2.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->scrapy) (1.17.1)\n",
            "Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (24.2.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (0.4.1)\n",
            "Collecting automat>=0.8.0 (from Twisted>=18.9.0->scrapy)\n",
            "  Downloading Automat-24.8.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting constantly>=15.1 (from Twisted>=18.9.0->scrapy)\n",
            "  Downloading constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting hyperlink>=17.1.1 (from Twisted>=18.9.0->scrapy)\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting incremental>=24.7.0 (from Twisted>=18.9.0->scrapy)\n",
            "  Downloading incremental-24.7.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from Twisted>=18.9.0->scrapy) (4.12.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (3.10)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (2.32.3)\n",
            "Collecting requests-file>=1.4 (from tldextract->scrapy)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (3.16.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.22)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from incremental>=24.7.0->Twisted>=18.9.0->scrapy) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->scrapy) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2024.8.30)\n",
            "Downloading Scrapy-2.11.2-py2.py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading itemadapter-0.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading itemloaders-1.3.1-py3-none-any.whl (12 kB)\n",
            "Downloading parsel-1.9.1-py2.py3-none-any.whl (17 kB)\n",
            "Downloading Protego-0.3.1-py2.py3-none-any.whl (8.5 kB)\n",
            "Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
            "Downloading queuelib-1.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading service_identity-24.1.0-py3-none-any.whl (12 kB)\n",
            "Downloading twisted-24.7.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading w3lib-2.2.1-py3-none-any.whl (21 kB)\n",
            "Downloading zope.interface-7.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Automat-24.8.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
            "Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading incremental-24.7.2-py3-none-any.whl (20 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: PyDispatcher, zope.interface, w3lib, queuelib, protego, jmespath, itemadapter, incremental, hyperlink, cssselect, constantly, automat, Twisted, requests-file, parsel, tldextract, service-identity, itemloaders, scrapy\n",
            "Successfully installed PyDispatcher-2.0.7 Twisted-24.7.0 automat-24.8.1 constantly-23.10.4 cssselect-1.2.0 hyperlink-21.0.0 incremental-24.7.2 itemadapter-0.9.0 itemloaders-1.3.1 jmespath-1.0.1 parsel-1.9.1 protego-0.3.1 queuelib-1.7.0 requests-file-2.1.0 scrapy-2.11.2 service-identity-24.1.0 tldextract-5.1.2 w3lib-2.2.1 zope.interface-7.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhPF9V3_Jyjv"
      },
      "source": [
        "# MILESTONE 1\n",
        "\n",
        "a) Create a _Scrapy_ project for this lab (**HINT:** Remember you can use the command `startproject`).\n",
        "\n",
        "b) Create a crawler/spider to the website [BACHELOR IN DATA SCIENCE AND ENGINEERING\n",
        "](https://www.uc3m.es/bachelor-degree/data-science).\n",
        "\n",
        "c) Add the code to the crawler to get PROGRAM header. **TIP:** Find the element tag with `id=\"program\"` and print the result.\n",
        "\n",
        "d) Add the code to the crawler to find the table inside PROGRAM for Course 1 - Semester 1 and print the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR58vq8AwZuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b668d3d3-4ebb-4bb9-cdec-a0249f6ad349"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/My Drive/Analitica Web/M1_scrapy'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSxPkZqb0rFV",
        "outputId": "c77cdf1e-5568-44c7-855d-ad7429dd082c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Analitica Web/M1_scrapy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcpQL0jgXBPq"
      },
      "source": [
        "import scrapy"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkBV7gekXBMB"
      },
      "source": [
        "# a\n",
        "!scrapy startproject my_scrapy_crawler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"my_scrapy_crawler\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy7G8EjA131H",
        "outputId": "ed25f14f-cdb3-41f0-d6fd-804008c4b8ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Analitica Web/M1_scrapy/my_scrapy_crawler/my_scrapy_crawler\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# b\n",
        "!scrapy genspider uni_spider https://www.uc3m.es/bachelor-degree/data-science"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LugS0BIk1-8d",
        "outputId": "08ed16ff-d3ab-4427-bd2d-55dbb59ba642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spider 'uni_spider' already exists in module:\n",
            "  my_scrapy_crawler.spiders.uni_spider\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#c print(response.xpath('//*[@id=\"program\"]').get())\n",
        "!scrapy crawl uni_spider"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc7aNHhP2HPY",
        "outputId": "386f5a95-4142-4704-e859-d90b7f3e559a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-19 09:28:28 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: my_scrapy_crawler)\n",
            "2024-09-19 09:28:28 [scrapy.utils.log] INFO: Versions: lxml 4.9.4.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.7.0, Python 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.1, Platform Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "2024-09-19 09:28:28 [scrapy.addons] INFO: Enabled addons:\n",
            "[]\n",
            "2024-09-19 09:28:28 [asyncio] DEBUG: Using selector: EpollSelector\n",
            "2024-09-19 09:28:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
            "2024-09-19 09:28:28 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
            "2024-09-19 09:28:28 [scrapy.extensions.telnet] INFO: Telnet Password: a3179770d08fc550\n",
            "2024-09-19 09:28:28 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2024-09-19 09:28:28 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'my_scrapy_crawler',\n",
            " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
            " 'NEWSPIDER_MODULE': 'my_scrapy_crawler.spiders',\n",
            " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['my_scrapy_crawler.spiders'],\n",
            " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
            "2024-09-19 09:28:29 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2024-09-19 09:28:29 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2024-09-19 09:28:29 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2024-09-19 09:28:29 [scrapy.core.engine] INFO: Spider opened\n",
            "2024-09-19 09:28:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2024-09-19 09:28:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2024-09-19 09:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.uc3m.es/robots.txt> (referer: None)\n",
            "2024-09-19 09:28:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.uc3m.es/bachelor-degree/data-science> (referer: None)\n",
            "<div class=\"marcoParrafo\" id=\"program\">\n",
            "\t\t\t\t\t\t\t<h2>Program</h2>\n",
            "\t\t\t\t\t\t</div>\n",
            "2024-09-19 09:28:30 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2024-09-19 09:28:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 462,\n",
            " 'downloader/request_count': 2,\n",
            " 'downloader/request_method_count/GET': 2,\n",
            " 'downloader/response_bytes': 18334,\n",
            " 'downloader/response_count': 2,\n",
            " 'downloader/response_status_count/200': 2,\n",
            " 'elapsed_time_seconds': 1.430154,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2024, 9, 19, 9, 28, 30, 571570, tzinfo=datetime.timezone.utc),\n",
            " 'httpcompression/response_bytes': 92807,\n",
            " 'httpcompression/response_count': 2,\n",
            " 'log_count/DEBUG': 5,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 128311296,\n",
            " 'memusage/startup': 128311296,\n",
            " 'response_received_count': 2,\n",
            " 'robotstxt/request_count': 1,\n",
            " 'robotstxt/response_count': 1,\n",
            " 'robotstxt/response_status_count/200': 1,\n",
            " 'scheduler/dequeued': 1,\n",
            " 'scheduler/dequeued/memory': 1,\n",
            " 'scheduler/enqueued': 1,\n",
            " 'scheduler/enqueued/memory': 1,\n",
            " 'start_time': datetime.datetime(2024, 9, 19, 9, 28, 29, 141416, tzinfo=datetime.timezone.utc)}\n",
            "2024-09-19 09:28:30 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#d\n",
        "# print(response.xpath(\"//*[@id='content']/div[2]/div[3]/div[2]/div/div[1]/div[1]/div[1]/table\").get())\n",
        "\n",
        "!scrapy crawl uni_spider"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYv3kpVM4ApE",
        "outputId": "932a86f7-eeca-43ca-d224-f2f3f7e0c382"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-23 07:33:11 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: my_scrapy_crawler)\n",
            "2024-09-23 07:33:11 [scrapy.utils.log] INFO: Versions: lxml 4.9.4.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.7.0, Python 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.1, Platform Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "2024-09-23 07:33:11 [scrapy.addons] INFO: Enabled addons:\n",
            "[]\n",
            "2024-09-23 07:33:11 [asyncio] DEBUG: Using selector: EpollSelector\n",
            "2024-09-23 07:33:11 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
            "2024-09-23 07:33:11 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
            "2024-09-23 07:33:11 [scrapy.extensions.telnet] INFO: Telnet Password: 31253e9a95be9df7\n",
            "2024-09-23 07:33:11 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2024-09-23 07:33:11 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'my_scrapy_crawler',\n",
            " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
            " 'NEWSPIDER_MODULE': 'my_scrapy_crawler.spiders',\n",
            " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['my_scrapy_crawler.spiders'],\n",
            " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
            "2024-09-23 07:33:11 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2024-09-23 07:33:11 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2024-09-23 07:33:11 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2024-09-23 07:33:11 [scrapy.core.engine] INFO: Spider opened\n",
            "2024-09-23 07:33:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2024-09-23 07:33:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2024-09-23 07:33:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.uc3m.es/robots.txt> (referer: None)\n",
            "2024-09-23 07:33:13 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): publicsuffix.org:443\n",
            "2024-09-23 07:33:13 [urllib3.connectionpool] DEBUG: https://publicsuffix.org:443 \"GET /list/public_suffix_list.dat HTTP/1.1\" 200 86660\n",
            "2024-09-23 07:33:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.uc3m.es/bachelor-degree/data-science> (referer: None)\n",
            "<table cellspacing=\"1\" cellpadding=\"1\" border=\"1\"><caption class=\"oculto\">General subjects</caption><thead><tr><th class=\"first\" id=\"Subjects-1-1-1371240957274\">Subjects</th><th id=\"ECTS-1-1-1371240957274\">ECTS</th><th id=\"TYPE-1-1-1371240957274\">TYPE</th><th id=\"Language-1-1-1371240957274\" class=\"last\">Language</th></tr></thead><tr><td data-label=\"Subject\" headers=\"Subjects-1-1-1371240957274\"><a href=\"https://aplicaciones.uc3m.es/cpa/generaFicha?&amp;est=350&amp;plan=392&amp;asig=16472&amp;idioma=2\"><span class=\"\">Calculus I</span></a></td><td data-label=\"ECTS\" headers=\"ECTS-1-1-1371240957274\"><span class=\"\">6</span></td><td data-label=\"TYPE\" headers=\"TYPE-1-1-1371240957274\"><span class=\"\">BC</span></td><td class=\"listaIdiomas\" data-label=\"Language\" headers=\"Language-1-1-1371240957274\"><img class=\"idioma_img\" src=\"/base/media/base/img/decorativa/IMG_Comunes_IdiomaEN_Square/ingles.jpg\" alt=\"English\"></td></tr><tr><td data-label=\"Subject\" headers=\"Subjects-1-1-1371240957274\"><a href=\"https://aplicaciones.uc3m.es/cpa/generaFicha?&amp;est=350&amp;plan=392&amp;asig=16475&amp;idioma=2\"><span class=\"\">Introduction to Data Science</span></a></td><td data-label=\"ECTS\" headers=\"ECTS-1-1-1371240957274\"><span class=\"\">6</span></td><td data-label=\"TYPE\" headers=\"TYPE-1-1-1371240957274\"><span class=\"\">BC</span></td><td class=\"listaIdiomas\" data-label=\"Language\" headers=\"Language-1-1-1371240957274\"><img class=\"idioma_img\" src=\"/base/media/base/img/decorativa/IMG_Comunes_IdiomaEN_Square/ingles.jpg\" alt=\"English\"></td></tr><tr><td data-label=\"Subject\" headers=\"Subjects-1-1-1371240957274\"><a href=\"https://aplicaciones.uc3m.es/cpa/generaFicha?&amp;est=350&amp;plan=392&amp;asig=16266&amp;idioma=2\"><span class=\"\">Linear algebra</span></a></td><td data-label=\"ECTS\" headers=\"ECTS-1-1-1371240957274\"><span class=\"\">6</span></td><td data-label=\"TYPE\" headers=\"TYPE-1-1-1371240957274\"><span class=\"\">BC</span></td><td class=\"listaIdiomas\" data-label=\"Language\" headers=\"Language-1-1-1371240957274\"><img class=\"idioma_img\" src=\"/base/media/base/img/decorativa/IMG_Comunes_IdiomaEN_Square/ingles.jpg\" alt=\"English\"></td></tr><tr><td data-label=\"Subject\" headers=\"Subjects-1-1-1371240957274\"><a href=\"https://aplicaciones.uc3m.es/cpa/generaFicha?&amp;est=350&amp;plan=392&amp;asig=16477&amp;idioma=2\"><span class=\"\">Probability and Data Analysis</span></a></td><td data-label=\"ECTS\" headers=\"ECTS-1-1-1371240957274\"><span class=\"\">6</span></td><td data-label=\"TYPE\" headers=\"TYPE-1-1-1371240957274\"><span class=\"\">BC</span></td><td class=\"listaIdiomas\" data-label=\"Language\" headers=\"Language-1-1-1371240957274\"><img class=\"idioma_img\" src=\"/base/media/base/img/decorativa/IMG_Comunes_IdiomaEN_Square/ingles.jpg\" alt=\"English\"></td></tr><tr><td data-label=\"Subject\" headers=\"Subjects-1-1-1371240957274\"><a href=\"https://aplicaciones.uc3m.es/cpa/generaFicha?&amp;est=350&amp;plan=392&amp;asig=16480&amp;idioma=2\"><span class=\"\">Programming</span></a></td><td data-label=\"ECTS\" headers=\"ECTS-1-1-1371240957274\"><span class=\"\">6</span></td><td data-label=\"TYPE\" headers=\"TYPE-1-1-1371240957274\"><span class=\"\">BC</span></td><td class=\"listaIdiomas\" data-label=\"Language\" headers=\"Language-1-1-1371240957274\"><img class=\"idioma_img\" src=\"/base/media/base/img/decorativa/IMG_Comunes_IdiomaEN_Square/ingles.jpg\" alt=\"English\"></td></tr></table>\n",
            "2024-09-23 07:33:13 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2024-09-23 07:33:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 462,\n",
            " 'downloader/request_count': 2,\n",
            " 'downloader/request_method_count/GET': 2,\n",
            " 'downloader/response_bytes': 18341,\n",
            " 'downloader/response_count': 2,\n",
            " 'downloader/response_status_count/200': 2,\n",
            " 'elapsed_time_seconds': 1.843557,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2024, 9, 23, 7, 33, 13, 754842, tzinfo=datetime.timezone.utc),\n",
            " 'httpcompression/response_bytes': 92807,\n",
            " 'httpcompression/response_count': 2,\n",
            " 'log_count/DEBUG': 7,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 126685184,\n",
            " 'memusage/startup': 126685184,\n",
            " 'response_received_count': 2,\n",
            " 'robotstxt/request_count': 1,\n",
            " 'robotstxt/response_count': 1,\n",
            " 'robotstxt/response_status_count/200': 1,\n",
            " 'scheduler/dequeued': 1,\n",
            " 'scheduler/dequeued/memory': 1,\n",
            " 'scheduler/enqueued': 1,\n",
            " 'scheduler/enqueued/memory': 1,\n",
            " 'start_time': datetime.datetime(2024, 9, 23, 7, 33, 11, 911285, tzinfo=datetime.timezone.utc)}\n",
            "2024-09-23 07:33:13 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHKtqTS95RSx"
      },
      "source": [
        "# MILESTONE 2\n",
        "\n",
        "a) Obtain the link to Web Analytics course by finding the corresponding href.\n",
        "\n",
        "b) Create a new spider _class_ and access to this URL.\n",
        "\n",
        "**TIP**: For this milestone, you need to create a new crawler and give it a different name.\n",
        "\n",
        "c) Print the text inside the _Description of contents: programme_ section.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7xkCvEVXDT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddfbd6d6-bafc-4065-986e-9a12919b4bb4"
      },
      "source": [
        "#a\n",
        "#print(response.xpath('//a[span[text()=\"Web Analytics\"]]/@href').get())\n",
        "\n",
        "!scrapy crawl uni_spider"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-18 16:16:56 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: my_scrapy_crawler)\n",
            "2024-09-18 16:16:56 [scrapy.utils.log] INFO: Versions: lxml 4.9.4.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.7.0, Python 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.1, Platform Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "2024-09-18 16:16:56 [scrapy.addons] INFO: Enabled addons:\n",
            "[]\n",
            "2024-09-18 16:16:56 [asyncio] DEBUG: Using selector: EpollSelector\n",
            "2024-09-18 16:16:56 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
            "2024-09-18 16:16:56 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
            "2024-09-18 16:16:56 [scrapy.extensions.telnet] INFO: Telnet Password: 72168ca8c04d05a5\n",
            "2024-09-18 16:16:56 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2024-09-18 16:16:56 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'my_scrapy_crawler',\n",
            " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
            " 'NEWSPIDER_MODULE': 'my_scrapy_crawler.spiders',\n",
            " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['my_scrapy_crawler.spiders'],\n",
            " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
            "2024-09-18 16:16:56 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2024-09-18 16:16:56 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2024-09-18 16:16:56 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2024-09-18 16:16:56 [scrapy.core.engine] INFO: Spider opened\n",
            "2024-09-18 16:16:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2024-09-18 16:16:56 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2024-09-18 16:16:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.uc3m.es/robots.txt> (referer: None)\n",
            "2024-09-18 16:16:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.uc3m.es/bachelor-degree/data-science> (referer: None)\n",
            "https://aplicaciones.uc3m.es/cpa/generaFicha?&est=350&plan=392&asig=16507&idioma=2\n",
            "2024-09-18 16:16:57 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2024-09-18 16:16:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 462,\n",
            " 'downloader/request_count': 2,\n",
            " 'downloader/request_method_count/GET': 2,\n",
            " 'downloader/response_bytes': 18349,\n",
            " 'downloader/response_count': 2,\n",
            " 'downloader/response_status_count/200': 2,\n",
            " 'elapsed_time_seconds': 1.018952,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2024, 9, 18, 16, 16, 57, 505528, tzinfo=datetime.timezone.utc),\n",
            " 'httpcompression/response_bytes': 92800,\n",
            " 'httpcompression/response_count': 2,\n",
            " 'log_count/DEBUG': 5,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 236167168,\n",
            " 'memusage/startup': 236167168,\n",
            " 'response_received_count': 2,\n",
            " 'robotstxt/request_count': 1,\n",
            " 'robotstxt/response_count': 1,\n",
            " 'robotstxt/response_status_count/200': 1,\n",
            " 'scheduler/dequeued': 1,\n",
            " 'scheduler/dequeued/memory': 1,\n",
            " 'scheduler/enqueued': 1,\n",
            " 'scheduler/enqueued/memory': 1,\n",
            " 'start_time': datetime.datetime(2024, 9, 18, 16, 16, 56, 486576, tzinfo=datetime.timezone.utc)}\n",
            "2024-09-18 16:16:57 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-yQti1TXDPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54df8462-5674-4ffc-c06a-4ac0efd840bf"
      },
      "source": [
        "#b\n",
        "!scrapy genspider class https://aplicaciones.uc3m.es/cpa/generaFicha?&est=350&plan=392&asig=16507&idioma=2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spider 'class' already exists in module:\n",
            "  my_scrapy_crawler.spiders.class\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtEwewGQXDNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04066319-2667-4803-866d-8a9ec131dab9"
      },
      "source": [
        "#c\n",
        "#print(response.xpath('//div[@class=\"panel panel-primary apartado\"]//div[@class=\"panel-heading degradado\" and contains(text(),\"Description of contents\")]/following-sibling::div[@class=\"panel-body\"]//div[@class=\"tarea\"]/text()').getall())\n",
        "\n",
        "!scrapy crawl class"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-18 16:22:39 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: my_scrapy_crawler)\n",
            "2024-09-18 16:22:39 [scrapy.utils.log] INFO: Versions: lxml 4.9.4.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.7.0, Python 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.1, Platform Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "2024-09-18 16:22:39 [scrapy.addons] INFO: Enabled addons:\n",
            "[]\n",
            "2024-09-18 16:22:39 [asyncio] DEBUG: Using selector: EpollSelector\n",
            "2024-09-18 16:22:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
            "2024-09-18 16:22:39 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
            "2024-09-18 16:22:39 [scrapy.extensions.telnet] INFO: Telnet Password: c7c3277753daf14a\n",
            "2024-09-18 16:22:39 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2024-09-18 16:22:39 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'my_scrapy_crawler',\n",
            " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
            " 'NEWSPIDER_MODULE': 'my_scrapy_crawler.spiders',\n",
            " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['my_scrapy_crawler.spiders'],\n",
            " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
            "2024-09-18 16:22:40 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2024-09-18 16:22:40 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2024-09-18 16:22:40 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2024-09-18 16:22:40 [scrapy.core.engine] INFO: Spider opened\n",
            "2024-09-18 16:22:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2024-09-18 16:22:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2024-09-18 16:22:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://aplicaciones.uc3m.es/robots.txt> (referer: None)\n",
            "2024-09-18 16:22:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://aplicaciones.uc3m.es/cpa/generaFicha?&est=350&plan=392&asig=16507&idioma=2> (referer: None)\n",
            "['1.\\tData Collection in the Web ecosystem: \\n        1.1  Scrapers, Crawlers\\n        1.2\\tAPIs\\n2.\\tData Analytics in the web\\n        2.1  Graph Analysis: Centrality and Influence metrics\\n        2.2  Network structure: \\n               2.2.1 Type of networks (bipartite graph, small world, scale free)\\n               2.2.2 Clustering, Community Detection, K-core decomposition\\n\\n3.\\tWeb data visualization\\n        3.1\\tRepresentation of web information.\\n        3.2\\tVisualization tools.\\n\\n4.\\tFinal Web Analytics Project\\n        4.1\\tThe project needs to include the three components presented above (Data Collection, Data Analytics and Data Visualization\\n']\n",
            "2024-09-18 16:22:42 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2024-09-18 16:22:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 505,\n",
            " 'downloader/request_count': 2,\n",
            " 'downloader/request_method_count/GET': 2,\n",
            " 'downloader/response_bytes': 8089,\n",
            " 'downloader/response_count': 2,\n",
            " 'downloader/response_status_count/200': 2,\n",
            " 'elapsed_time_seconds': 1.755645,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2024, 9, 18, 16, 22, 42, 13160, tzinfo=datetime.timezone.utc),\n",
            " 'httpcompression/response_bytes': 17988,\n",
            " 'httpcompression/response_count': 2,\n",
            " 'log_count/DEBUG': 5,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 238059520,\n",
            " 'memusage/startup': 238059520,\n",
            " 'response_received_count': 2,\n",
            " 'robotstxt/request_count': 1,\n",
            " 'robotstxt/response_count': 1,\n",
            " 'robotstxt/response_status_count/200': 1,\n",
            " 'scheduler/dequeued': 1,\n",
            " 'scheduler/dequeued/memory': 1,\n",
            " 'scheduler/enqueued': 1,\n",
            " 'scheduler/enqueued/memory': 1,\n",
            " 'start_time': datetime.datetime(2024, 9, 18, 16, 22, 40, 257515, tzinfo=datetime.timezone.utc)}\n",
            "2024-09-18 16:22:42 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN4L9SxRP3Hj"
      },
      "source": [
        "# MILESTONE 3\n",
        "\n",
        "a) Modify your code from previous milestones for running both crawlers in the same command line process.\n",
        "\n",
        "\n",
        "b) Instead of printing the results (from Milestone 1 and 2), save them in a file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G84E8DrUXFwt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ccbd79e-2716-438f-a9fa-da0012976b2a"
      },
      "source": [
        "#a\n",
        "!scrapy crawl uni_spider && scrapy crawl class\n",
        "#if we add only one & then they are run in parallel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-18 16:25:11 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: my_scrapy_crawler)\n",
            "2024-09-18 16:25:11 [scrapy.utils.log] INFO: Versions: lxml 4.9.4.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.7.0, Python 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.1, Platform Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "2024-09-18 16:25:11 [scrapy.addons] INFO: Enabled addons:\n",
            "[]\n",
            "2024-09-18 16:25:11 [asyncio] DEBUG: Using selector: EpollSelector\n",
            "2024-09-18 16:25:11 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
            "2024-09-18 16:25:11 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
            "2024-09-18 16:25:11 [scrapy.extensions.telnet] INFO: Telnet Password: c7378e2d74f2a9b2\n",
            "2024-09-18 16:25:11 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2024-09-18 16:25:11 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'my_scrapy_crawler',\n",
            " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
            " 'NEWSPIDER_MODULE': 'my_scrapy_crawler.spiders',\n",
            " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['my_scrapy_crawler.spiders'],\n",
            " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
            "2024-09-18 16:25:12 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2024-09-18 16:25:12 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2024-09-18 16:25:12 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2024-09-18 16:25:12 [scrapy.core.engine] INFO: Spider opened\n",
            "2024-09-18 16:25:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2024-09-18 16:25:12 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2024-09-18 16:25:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.uc3m.es/robots.txt> (referer: None)\n",
            "2024-09-18 16:25:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.uc3m.es/bachelor-degree/data-science> (referer: None)\n",
            "https://aplicaciones.uc3m.es/cpa/generaFicha?&est=350&plan=392&asig=16507&idioma=2\n",
            "2024-09-18 16:25:13 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2024-09-18 16:25:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 462,\n",
            " 'downloader/request_count': 2,\n",
            " 'downloader/request_method_count/GET': 2,\n",
            " 'downloader/response_bytes': 18338,\n",
            " 'downloader/response_count': 2,\n",
            " 'downloader/response_status_count/200': 2,\n",
            " 'elapsed_time_seconds': 1.313318,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2024, 9, 18, 16, 25, 13, 508628, tzinfo=datetime.timezone.utc),\n",
            " 'httpcompression/response_bytes': 92800,\n",
            " 'httpcompression/response_count': 2,\n",
            " 'log_count/DEBUG': 5,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 68128768,\n",
            " 'memusage/startup': 68128768,\n",
            " 'response_received_count': 2,\n",
            " 'robotstxt/request_count': 1,\n",
            " 'robotstxt/response_count': 1,\n",
            " 'robotstxt/response_status_count/200': 1,\n",
            " 'scheduler/dequeued': 1,\n",
            " 'scheduler/dequeued/memory': 1,\n",
            " 'scheduler/enqueued': 1,\n",
            " 'scheduler/enqueued/memory': 1,\n",
            " 'start_time': datetime.datetime(2024, 9, 18, 16, 25, 12, 195310, tzinfo=datetime.timezone.utc)}\n",
            "2024-09-18 16:25:13 [scrapy.core.engine] INFO: Spider closed (finished)\n",
            "2024-09-18 16:25:14 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: my_scrapy_crawler)\n",
            "2024-09-18 16:25:14 [scrapy.utils.log] INFO: Versions: lxml 4.9.4.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.7.0, Python 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.1, Platform Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "2024-09-18 16:25:14 [scrapy.addons] INFO: Enabled addons:\n",
            "[]\n",
            "2024-09-18 16:25:14 [asyncio] DEBUG: Using selector: EpollSelector\n",
            "2024-09-18 16:25:14 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
            "2024-09-18 16:25:14 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
            "2024-09-18 16:25:14 [scrapy.extensions.telnet] INFO: Telnet Password: 846ca5ec55e10c24\n",
            "2024-09-18 16:25:14 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2024-09-18 16:25:14 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'my_scrapy_crawler',\n",
            " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
            " 'NEWSPIDER_MODULE': 'my_scrapy_crawler.spiders',\n",
            " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['my_scrapy_crawler.spiders'],\n",
            " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
            "2024-09-18 16:25:14 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2024-09-18 16:25:14 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2024-09-18 16:25:14 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2024-09-18 16:25:14 [scrapy.core.engine] INFO: Spider opened\n",
            "2024-09-18 16:25:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2024-09-18 16:25:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2024-09-18 16:25:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://aplicaciones.uc3m.es/robots.txt> (referer: None)\n",
            "2024-09-18 16:25:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://aplicaciones.uc3m.es/cpa/generaFicha?&est=350&plan=392&asig=16507&idioma=2> (referer: None)\n",
            "['1.\\tData Collection in the Web ecosystem: \\n        1.1  Scrapers, Crawlers\\n        1.2\\tAPIs\\n2.\\tData Analytics in the web\\n        2.1  Graph Analysis: Centrality and Influence metrics\\n        2.2  Network structure: \\n               2.2.1 Type of networks (bipartite graph, small world, scale free)\\n               2.2.2 Clustering, Community Detection, K-core decomposition\\n\\n3.\\tWeb data visualization\\n        3.1\\tRepresentation of web information.\\n        3.2\\tVisualization tools.\\n\\n4.\\tFinal Web Analytics Project\\n        4.1\\tThe project needs to include the three components presented above (Data Collection, Data Analytics and Data Visualization\\n']\n",
            "2024-09-18 16:25:15 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2024-09-18 16:25:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 505,\n",
            " 'downloader/request_count': 2,\n",
            " 'downloader/request_method_count/GET': 2,\n",
            " 'downloader/response_bytes': 8089,\n",
            " 'downloader/response_count': 2,\n",
            " 'downloader/response_status_count/200': 2,\n",
            " 'elapsed_time_seconds': 1.115941,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2024, 9, 18, 16, 25, 15, 964172, tzinfo=datetime.timezone.utc),\n",
            " 'httpcompression/response_bytes': 17988,\n",
            " 'httpcompression/response_count': 2,\n",
            " 'log_count/DEBUG': 5,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 238059520,\n",
            " 'memusage/startup': 238059520,\n",
            " 'response_received_count': 2,\n",
            " 'robotstxt/request_count': 1,\n",
            " 'robotstxt/response_count': 1,\n",
            " 'robotstxt/response_status_count/200': 1,\n",
            " 'scheduler/dequeued': 1,\n",
            " 'scheduler/dequeued/memory': 1,\n",
            " 'scheduler/enqueued': 1,\n",
            " 'scheduler/enqueued/memory': 1,\n",
            " 'start_time': datetime.datetime(2024, 9, 18, 16, 25, 14, 848231, tzinfo=datetime.timezone.utc)}\n",
            "2024-09-18 16:25:15 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWzVuLtSXFo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7bf9728-6400-46d3-df67-539e046fd20f"
      },
      "source": [
        "#b\n",
        "\n",
        "#class:\n",
        "#yield{ 'text':response.xpath('//div[@class=\"panel panel-primary apartado\"]//div[@class=\"panel-heading degradado\" and contains(text(),\"Description of contents\")]/following-sibling::div[@class=\"panel-body\"]//div[@class=\"tarea\"]/text()').getall()}\n",
        "\n",
        "#uni:\n",
        "#yield{'url': response.xpath('//a[span[text()=\"Web Analytics\"]]/@href').get()\n",
        "#}\n",
        "!scrapy crawl uni_spider -O results_uni.json && scrapy crawl class -O results_class.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-18 16:31:17 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: my_scrapy_crawler)\n",
            "2024-09-18 16:31:17 [scrapy.utils.log] INFO: Versions: lxml 4.9.4.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.7.0, Python 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.1, Platform Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "2024-09-18 16:31:17 [scrapy.addons] INFO: Enabled addons:\n",
            "[]\n",
            "2024-09-18 16:31:17 [asyncio] DEBUG: Using selector: EpollSelector\n",
            "2024-09-18 16:31:17 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
            "2024-09-18 16:31:17 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
            "2024-09-18 16:31:17 [scrapy.extensions.telnet] INFO: Telnet Password: 15bfbedceea9f251\n",
            "2024-09-18 16:31:17 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.feedexport.FeedExporter',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2024-09-18 16:31:17 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'my_scrapy_crawler',\n",
            " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
            " 'NEWSPIDER_MODULE': 'my_scrapy_crawler.spiders',\n",
            " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['my_scrapy_crawler.spiders'],\n",
            " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
            "2024-09-18 16:31:17 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2024-09-18 16:31:17 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2024-09-18 16:31:17 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2024-09-18 16:31:17 [scrapy.core.engine] INFO: Spider opened\n",
            "2024-09-18 16:31:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2024-09-18 16:31:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2024-09-18 16:31:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.uc3m.es/robots.txt> (referer: None)\n",
            "2024-09-18 16:31:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.uc3m.es/bachelor-degree/data-science> (referer: None)\n",
            "2024-09-18 16:31:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.uc3m.es/bachelor-degree/data-science>\n",
            "{'url': 'https://aplicaciones.uc3m.es/cpa/generaFicha?&est=350&plan=392&asig=16507&idioma=2'}\n",
            "2024-09-18 16:31:18 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2024-09-18 16:31:18 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: results_uni.json\n",
            "2024-09-18 16:31:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 462,\n",
            " 'downloader/request_count': 2,\n",
            " 'downloader/request_method_count/GET': 2,\n",
            " 'downloader/response_bytes': 18351,\n",
            " 'downloader/response_count': 2,\n",
            " 'downloader/response_status_count/200': 2,\n",
            " 'elapsed_time_seconds': 1.063805,\n",
            " 'feedexport/success_count/FileFeedStorage': 1,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2024, 9, 18, 16, 31, 18, 543330, tzinfo=datetime.timezone.utc),\n",
            " 'httpcompression/response_bytes': 92807,\n",
            " 'httpcompression/response_count': 2,\n",
            " 'item_scraped_count': 1,\n",
            " 'log_count/DEBUG': 6,\n",
            " 'log_count/INFO': 11,\n",
            " 'memusage/max': 68063232,\n",
            " 'memusage/startup': 68063232,\n",
            " 'response_received_count': 2,\n",
            " 'robotstxt/request_count': 1,\n",
            " 'robotstxt/response_count': 1,\n",
            " 'robotstxt/response_status_count/200': 1,\n",
            " 'scheduler/dequeued': 1,\n",
            " 'scheduler/dequeued/memory': 1,\n",
            " 'scheduler/enqueued': 1,\n",
            " 'scheduler/enqueued/memory': 1,\n",
            " 'start_time': datetime.datetime(2024, 9, 18, 16, 31, 17, 479525, tzinfo=datetime.timezone.utc)}\n",
            "2024-09-18 16:31:18 [scrapy.core.engine] INFO: Spider closed (finished)\n",
            "2024-09-18 16:31:19 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: my_scrapy_crawler)\n",
            "2024-09-18 16:31:19 [scrapy.utils.log] INFO: Versions: lxml 4.9.4.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.7.0, Python 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.1, Platform Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "2024-09-18 16:31:19 [scrapy.addons] INFO: Enabled addons:\n",
            "[]\n",
            "2024-09-18 16:31:19 [asyncio] DEBUG: Using selector: EpollSelector\n",
            "2024-09-18 16:31:19 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
            "2024-09-18 16:31:19 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
            "2024-09-18 16:31:19 [scrapy.extensions.telnet] INFO: Telnet Password: 8acd114d3f503600\n",
            "2024-09-18 16:31:19 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.feedexport.FeedExporter',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2024-09-18 16:31:19 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'my_scrapy_crawler',\n",
            " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
            " 'NEWSPIDER_MODULE': 'my_scrapy_crawler.spiders',\n",
            " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['my_scrapy_crawler.spiders'],\n",
            " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
            "2024-09-18 16:31:19 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2024-09-18 16:31:19 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2024-09-18 16:31:19 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2024-09-18 16:31:19 [scrapy.core.engine] INFO: Spider opened\n",
            "2024-09-18 16:31:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2024-09-18 16:31:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2024-09-18 16:31:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://aplicaciones.uc3m.es/robots.txt> (referer: None)\n",
            "2024-09-18 16:31:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://aplicaciones.uc3m.es/cpa/generaFicha?&est=350&plan=392&asig=16507&idioma=2> (referer: None)\n",
            "2024-09-18 16:31:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://aplicaciones.uc3m.es/cpa/generaFicha?&est=350&plan=392&asig=16507&idioma=2>\n",
            "{'text': ['1.\\tData Collection in the Web ecosystem: \\n        1.1  Scrapers, Crawlers\\n        1.2\\tAPIs\\n2.\\tData Analytics in the web\\n        2.1  Graph Analysis: Centrality and Influence metrics\\n        2.2  Network structure: \\n               2.2.1 Type of networks (bipartite graph, small world, scale free)\\n               2.2.2 Clustering, Community Detection, K-core decomposition\\n\\n3.\\tWeb data visualization\\n        3.1\\tRepresentation of web information.\\n        3.2\\tVisualization tools.\\n\\n4.\\tFinal Web Analytics Project\\n        4.1\\tThe project needs to include the three components presented above (Data Collection, Data Analytics and Data Visualization\\n']}\n",
            "2024-09-18 16:31:20 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2024-09-18 16:31:21 [scrapy.extensions.feedexport] INFO: Stored json feed (1 items) in: results_class.json\n",
            "2024-09-18 16:31:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 505,\n",
            " 'downloader/request_count': 2,\n",
            " 'downloader/request_method_count/GET': 2,\n",
            " 'downloader/response_bytes': 8089,\n",
            " 'downloader/response_count': 2,\n",
            " 'downloader/response_status_count/200': 2,\n",
            " 'elapsed_time_seconds': 1.184827,\n",
            " 'feedexport/success_count/FileFeedStorage': 1,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2024, 9, 18, 16, 31, 20, 998762, tzinfo=datetime.timezone.utc),\n",
            " 'httpcompression/response_bytes': 17988,\n",
            " 'httpcompression/response_count': 2,\n",
            " 'item_scraped_count': 1,\n",
            " 'log_count/DEBUG': 6,\n",
            " 'log_count/INFO': 11,\n",
            " 'memusage/max': 239411200,\n",
            " 'memusage/startup': 239411200,\n",
            " 'response_received_count': 2,\n",
            " 'robotstxt/request_count': 1,\n",
            " 'robotstxt/response_count': 1,\n",
            " 'robotstxt/response_status_count/200': 1,\n",
            " 'scheduler/dequeued': 1,\n",
            " 'scheduler/dequeued/memory': 1,\n",
            " 'scheduler/enqueued': 1,\n",
            " 'scheduler/enqueued/memory': 1,\n",
            " 'start_time': datetime.datetime(2024, 9, 18, 16, 31, 19, 813935, tzinfo=datetime.timezone.utc)}\n",
            "2024-09-18 16:31:21 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "628IW9k1XFl8"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}